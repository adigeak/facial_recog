{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "voilajonnes.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP0dUSQ/wRTdJUF535yAkzE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adigeak/facial_recog/blob/master/voilajonnes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4yHAhomag9m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import scipy as sp\n",
        "import math\n",
        "from sklearn.feature_selection import SelectPercentile,f_classif"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtkBimJelFTb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def integral_image(image): # we have an image as an Numpy array\n",
        "    '''\n",
        "    This function to make the integral image which is the clever way \n",
        "    of storing images as we have to find the summation of all the\n",
        "    pixel again and again as this task is require high computation\n",
        "    power. To easy it little bit we use the integral image.\n",
        "    '''\n",
        "    print(image.shape)\n",
        "    print(len(image))\n",
        "    print(len(image[0]))\n",
        "    ii = np.zeros(image.shape)\n",
        "    s = np.zeros(image.shape)\n",
        "    for y in range(len(image)):\n",
        "        for x in range(len(image[y])): # doubt\n",
        "            s[y][x]= s[y-1][x] + image[y][x] if y-1 >= 0 else image[y][x]\n",
        "            ii[y][x] = ii[y][x-1] + s[y][x] if x-1 >= 0 else s[y][x]\n",
        "    return ii"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5zcUoR5H9MN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RectangeleRegion:\n",
        "    def __init__(self,x,y,width,height):\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "        self.width = width\n",
        "        self.height = height\n",
        "\n",
        "    def compute_feature(self, ii):\n",
        "        return ii[self.y + self.height][self.x + self.widht] + ii[self.y][self.x] - (ii[self.y+self.height][self.x]+ii[self.y][self.x+self.width])\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PsYNmiaGrMhE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# i = np.ones((4,5))\n",
        "# print(integral_image(i))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWGEgIvYy_jV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ViolaJones:\n",
        "    def __init__(self, T = 10):\n",
        "        \"\"\"\n",
        "        This function is used to define the number of weak classifer that\n",
        "        the algorithm is going to use to create strong classifier using \n",
        "        adaboost.\n",
        "        \"\"\"\n",
        "        self.T = T\n",
        "        self.alphas = []\n",
        "        self.clfs = []\n",
        "\n",
        "    def train(self, training, pos_num, neg_num):\n",
        "        training_data = []\n",
        "        weights = np.zeros(len(training))\n",
        "        for x in range(len(training)):\n",
        "            traning_data.append((integral_image(training[x][0]),training[x][1])) # [x][1] is the classification of\n",
        "            # Image is positive 1 and negative 0\n",
        "            # if positive use 1/2*p where p is the number of positive classes and same for negative\n",
        "            if training[x][1] == 1:\n",
        "                weights[x] = 1.0 / (2 * pos_num)\n",
        "            else:\n",
        "                weights[x] = 1.0 / (2 * neg_num)\n",
        "        features = self.build_features(training_data[0][0].shape)\n",
        "        X, y = self.apply_features(features,training_data)\n",
        "        indices = SelectPercentile(f_classif, percentile=10).fit(X.T, y).get_support(indices=True)\n",
        "        X = X[indices]\n",
        "        features = features[indices]\n",
        "        for t in range(self.T):\n",
        "            weights = weights / np.linalg.norm(weights) # normalize wight\n",
        "            weak_classifiers = self.train_weak(X, y, features, weights)\n",
        "            clf, error, accuracy = self.select_best(weak_classifiers, weights, training_data)\n",
        "            beta = error / (1.0 - error)\n",
        "            for i in range(len(accuracy)):\n",
        "                weights[i] = weights[i] * (beta ** (1 - accuracy[i]))\n",
        "                alpha = math.log(1.0/beta)\n",
        "                self.alphas.append(alpha)\n",
        "                self.clfs.append(clf)\n",
        "\n",
        "    \n",
        "    def train_weak(self, X, y, features, weights):\n",
        "        total_pos, total_neg = 0, 0\n",
        "        for w, label in zip(weights, y):\n",
        "            if label == 1:\n",
        "                total_pos += w\n",
        "            else:\n",
        "                total_neg += w\n",
        "\n",
        "        classifiers = []\n",
        "        total_features = X.shape[0]\n",
        "        for index, feature in enumerate(X):\n",
        "            if len(classifiers) % 1000 == 0 and len(classifiers) != 0:\n",
        "                print(\"Trained %d classifiers out of %d\" % (len(classifiers), total_features))\n",
        "            applied_feature = sorted(zip(weights, feature, y), key=lambda x: x[1])\n",
        "            pos_seen, neg_seen = 0, 0\n",
        "            pos_weights, neg_weights = 0, 0\n",
        "            min_error, best_feature, best_threshold, best_polarity = float('inf'), None, None, None\n",
        "            for w, f, label in applied_feature:\n",
        "                error = min(neg_weights + total_pos - pos_weights, pos_weights + total_neg - neg_weights)\n",
        "                if error < min_error:\n",
        "                    min_error = error\n",
        "                    best_feature = features[index]\n",
        "                    best_threshold = f\n",
        "                    best_polarity = 1 if pos_seen > neg_seen else -1\n",
        "                if label == 1:\n",
        "                    pos_seen += 1\n",
        "                    pos_weights += w\n",
        "                else:\n",
        "                    neg_seen += 1\n",
        "                    neg_weights += w\n",
        "            clf = WeakClassifier(best_feature[0], best_feature[1], best_threshold, best_polarity)\n",
        "            classifiers.append(clf)\n",
        "        return classifiers\n",
        "\n",
        "    def select_best(self, classifiers, weights, trainig_data):\n",
        "        best_clf, best_error, best_accuracy = None, float('inf'), None\n",
        "        for clf in classifiers:\n",
        "            error, accuracy = 0, []\n",
        "            for data, w in zip(training_data, weights):\n",
        "                correctness = abs(clf.classify(data[0]) - data[1])\n",
        "                accuracy.append(correctness)\n",
        "                error += w * correctness\n",
        "            error = error / len(training_data)\n",
        "            if error < best_error:\n",
        "                best_clf, best_error, best_accuracy = clf, error, accuracy\n",
        "        return best_clf, best_error, best_accuracy\n",
        "\n",
        "    def build_features(self, image_shape):\n",
        "        height, width = image_shape\n",
        "        features = []\n",
        "        for w in range(1,width+1):\n",
        "            for h in range(1,height+1):\n",
        "                i = 0\n",
        "                while i + w < width:\n",
        "                    j = 0\n",
        "                    while j + h < height:\n",
        "                        #2 rectangle features\n",
        "                        immediate = RectangleRegion(i, j, w, h)\n",
        "                        right = RectangleRegion(i+w, j, w, h)\n",
        "                        if i + 2 * w < width: #Horizontally Adjacent\n",
        "                            features.append(([right], [immediate]))\n",
        "\n",
        "                        bottom = RectangleRegion(i, j+h, w, h)\n",
        "                        if j + 2 * h < height: #Vertically Adjacent\n",
        "                            features.append(([immediate], [bottom]))\n",
        "                        \n",
        "                        right_2 = RectangleRegion(i+2*w, j, w, h)\n",
        "                        #3 rectangle features\n",
        "                        if i + 3 * w < width: #Horizontally Adjacent\n",
        "                            features.append(([right], [right_2, immediate]))\n",
        "\n",
        "                        bottom_2 = RectangleRegion(i, j+2*h, w, h)\n",
        "                        if j + 3 * h < height: #Vertically Adjacent\n",
        "                            features.append(([bottom], [bottom_2, immediate]))\n",
        "\n",
        "                        #4 rectangle features\n",
        "                        bottom_right = RectangleRegion(i+w, j+h, w, h)\n",
        "                        if i + 2 * w < width and j + 2 * h < height:\n",
        "                            features.append(([right, bottom], [immediate, bottom_right]))\n",
        "                        # we have use 4 Haar feature. 2 with two rectangle, 3 rectalge features\n",
        "                        # 4 rectangle feature\n",
        "                        j += 1\n",
        "                    i += 1\n",
        "        \n",
        "        return np.array(features) # we can modify here becoz it had added all features\n",
        "    \n",
        "    def apply_features(self, features, trainDf): # this is like selecting the best feature \n",
        "    # before training\n",
        "        X = np.zeros((len(features),len(trainDf)))\n",
        "        Y = np.array(map(lambda d: d[1], trainDf))\n",
        "        i = 0\n",
        "        for pos_reg, neg_reg in features:\n",
        "            feature = lambda ii: sum([pos.compute_feature(ii) for pos in positive_regions]) - sum([neg.compute_feature(ii) for neg in negative_regions])\n",
        "            X[i] = list(map(lambda d: feature(d[0]), trainDF))\n",
        "            i += 1\n",
        "        return X,Y\n",
        "    def classify(self, image):\n",
        "        total = 0\n",
        "        ii = integral_image(image)\n",
        "        for alpha,clf in zip(self.alphas, self.clfs):\n",
        "            total += alpha * clf.classify(ii)\n",
        "        return 1 if total >= 0.5 * sum(self.alphas) else 0\n",
        "\n",
        "    def save(self, filename):\n",
        "        with open(filename+\".pkl\", 'wb') as f:\n",
        "            pickle.dump(self, f)\n",
        "    \n",
        "    @staticmethod\n",
        "    def load(filename):\n",
        "        with open(filename+\".pkl\", 'rb') as f:\n",
        "            return pickle.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eldI-wpELMOU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class WeakClassifier:\n",
        "    def __init__(self, pos_reg, neg_reg, thres, polarity):\n",
        "        self.pos_reg = pos_reg\n",
        "        self.neg_reg = neg_reg\n",
        "        self.thres = thres\n",
        "        self.polarity = polarity\n",
        "\n",
        "    def classify(self, x):\n",
        "        feature = lambda ii: sum([pos.compute_feature(ii) for pos in positive_regions]) - sum([neg.compute_feature(ii) for neg in negative_regions])\n",
        "        return 1 if self.polarity * feature(x) < self.polarity * self.thres else 0   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qo2k_BbDxd05",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(t):\n",
        "    with open(\"training.pkl\", 'rb') as f:\n",
        "        training = pickle.load(f)\n",
        "    clf = ViolaJones(T=t)\n",
        "    clf.train(training, 2429, 4548)\n",
        "    evaluate(clf, training)\n",
        "    clf.save(str(t))\n",
        "\n",
        "def test(filename):\n",
        "    with open(\"test.pkl\", 'rb') as f:\n",
        "        test = pickle.load(f)\n",
        "    clf = ViolaJones.load(filename)\n",
        "    evaluate(clf, test)\n",
        "\n",
        "def evaluate(clf, data):\n",
        "    correct = 0\n",
        "    for x, y in data:\n",
        "        correct += 1 if clf.classify(x) == y else 0\n",
        "    print(\"Classified %d out of %d test examples\" % (correct, len(data)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJXSe7D5xwir",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "825620a3-781d-4a03-9343-65f892b56de8"
      },
      "source": [
        "train(10)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-84557d09d340>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-11-8373ab2fef9e>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"training.pkl\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0mtraining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mViolaJones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2429\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4548\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'training.pkl'"
          ]
        }
      ]
    }
  ]
}